{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":117336,"databundleVersionId":14027336,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# BLOCK 1 — Setup & Data (stable, safe normalization, and correct autocast setup)\n\nimport os, math, random, time, pickle, json\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nimport torch\nfrom torch import nn, Tensor\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torch.backends import cudnn\nfrom torch import optim, GradScaler\nfrom torchvision.transforms import v2\n\n# ✅ Correct device and autocast setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nenable_half = device.type == \"cuda\"\nscaler = GradScaler(enabled=enable_half)\nprint(\"Grad scaler is enabled:\", enable_half)\nprint(\"Device:\", device)\n\n# ✅ Stable seed & deterministic control\nseed = 1337\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif device.type == \"cuda\":\n    torch.cuda.manual_seed_all(seed)\ncudnn.benchmark = True\ntry:\n    torch.set_float32_matmul_precision(\"high\")\nexcept Exception:\n    pass\n\n# === File paths ===\nif os.path.exists(\"/kaggle/input\") and os.path.exists(\"/kaggle/working\"):\n    SVHN_test = \"/kaggle/input/fii-atnn-2025-competition-2/SVHN_test.pkl\"\n    SVHN_train = \"/kaggle/input/fii-atnn-2025-competition-2/SVHN_train.pkl\"\n    STATS_PATH = \"/kaggle/working/svhn_stats.json\"\nelse:\n    SVHN_test = \"data/SVHN_test.pkl\"\n    SVHN_train = \"data/SVHN_train.pkl\"\n    STATS_PATH = \"svhn_stats.json\"\n\n\n# === Dataset classes ===\nclass SVHN_Dataset(Dataset):\n    def __init__(self, train: bool, transforms: v2.Transform):\n        path = SVHN_train if train else SVHN_test\n        with open(path, \"rb\") as fd:\n            self.data = pickle.load(fd)\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, i: int):\n        image, label = self.data[i]\n        if self.transforms is None:\n            return image, label\n        x = self.transforms(image)\n        if torch.isnan(x).any() or torch.isinf(x).any():\n            # ✅ Skip bad samples\n            x = torch.clamp(x, 0, 1)\n        return x, label\n\n\nclass TransformedSubset(torch.utils.data.Subset):\n    def __init__(self, subset, transform):\n        super().__init__(subset.dataset, subset.indices)\n        self.transform = transform\n\n    def __getitem__(self, idx):\n        image, label = self.dataset[self.indices[idx]]\n        if self.transform is None:\n            return image, label\n        x = self.transform(image)\n        if torch.isnan(x).any() or torch.isinf(x).any():\n            x = torch.clamp(x, 0, 1)\n        return x, label\n\n\n# === Compute or load dataset mean/std safely ===\ndef compute_mean_std_from_dataset(dataset):\n    to_tensor = v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])\n    n_pixels = 0\n    sum_c = torch.zeros(3, dtype=torch.float64)\n    sumsq_c = torch.zeros(3, dtype=torch.float64)\n\n    for i in tqdm(range(len(dataset)), desc=\"Computing mean/std\", leave=False):\n        img, _ = dataset[i]\n        t = to_tensor(img)\n        c, h, w = t.shape\n        n = h * w\n        n_pixels += n\n        t = t.to(torch.float64)\n        sum_c += t.reshape(c, -1).sum(dim=1)\n        sumsq_c += (t.reshape(c, -1) ** 2).sum(dim=1)\n\n    mean = (sum_c / n_pixels).to(torch.float32)\n    var = (sumsq_c / n_pixels) - (mean.to(torch.float64) ** 2)\n    std = torch.sqrt(var.clamp_min(1e-6)).to(torch.float32)\n    return mean.tolist(), std.tolist()\n\n\nif os.path.exists(STATS_PATH):\n    with open(STATS_PATH, \"r\") as f:\n        stats = json.load(f)\n    mean, std = stats[\"mean\"], stats[\"std\"]\n    print(f\"Loaded stats: mean={mean}, std={std}\")\nelse:\n    base_train_for_stats = SVHN_Dataset(train=True, transforms=None)\n    mean, std = compute_mean_std_from_dataset(base_train_for_stats)\n    with open(STATS_PATH, \"w\") as f:\n        json.dump({\"mean\": mean, \"std\": std}, f)\n    print(f\"Computed stats: mean={mean}, std={std}\")\n\n# ✅ Sanity check and clamp bad stats\nmean = tuple(float(m) for m in mean)\nstd = tuple(max(float(s), 1e-3) for s in std)\nprint(f\"Using mean={mean}, std={std}\")\n\n\n# === Augmentations ===\ntrain_transforms = v2.Compose([\n    v2.ToImage(),\n    v2.RandomCrop(32, padding=4, padding_mode=\"reflect\"),\n    v2.RandomAffine(degrees=10, translate=(0.12, 0.12), scale=(0.9, 1.1)),\n    v2.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.07),\n    v2.ToDtype(torch.float32, scale=True),  # ✅ single scaling only\n    v2.Normalize(mean, std, inplace=True),\n    v2.RandomErasing(p=0.4, scale=(0.02, 0.15), ratio=(0.3, 3.3), inplace=True),\n    v2.RandAugment(num_ops=2, magnitude=9),\n])\n\neval_transforms = v2.Compose([\n    v2.ToImage(),\n    v2.ToDtype(torch.float32, scale=True),  # ✅ only one scaling op\n    v2.Normalize(mean, std, inplace=True),\n])\n\n\n# === Dataset and loaders ===\nbase_train = SVHN_Dataset(train=True, transforms=None)\nval_ratio = 0.10\nval_len = int(len(base_train) * val_ratio)\ntrain_len = len(base_train) - val_len\ntrain_subset, val_subset = random_split(base_train, [train_len, val_len], generator=torch.Generator().manual_seed(seed))\n\ntrain_set = TransformedSubset(train_subset, train_transforms)\nval_set = TransformedSubset(val_subset, eval_transforms)\ntest_set = SVHN_Dataset(train=False, transforms=eval_transforms)\n\nBATCH_SIZE = 256\nNUM_WORKERS = min(4, (os.cpu_count() or 2) // 2)\npin = device.type == \"cuda\"\n\ntrain_loader = DataLoader(\n    train_set, batch_size=BATCH_SIZE, shuffle=True,\n    num_workers=NUM_WORKERS, pin_memory=pin, persistent_workers=NUM_WORKERS > 0, drop_last=True\n)\nval_loader = DataLoader(\n    val_set, batch_size=512, shuffle=False,\n    num_workers=NUM_WORKERS, pin_memory=pin, persistent_workers=NUM_WORKERS > 0\n)\ntest_loader = DataLoader(\n    test_set, batch_size=1024, shuffle=False,\n    num_workers=NUM_WORKERS, pin_memory=pin, persistent_workers=NUM_WORKERS > 0\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T23:22:58.478844Z","iopub.execute_input":"2025-10-29T23:22:58.479619Z","iopub.status.idle":"2025-10-29T23:23:02.438389Z","shell.execute_reply.started":"2025-10-29T23:22:58.479593Z","shell.execute_reply":"2025-10-29T23:23:02.437568Z"}},"outputs":[{"name":"stdout","text":"Grad scaler is enabled: True\nDevice: cuda\nLoaded stats: mean=[0.5070751905441284, 0.48654890060424805, 0.44091787934303284], std=[0.2673342823982239, 0.2564384639263153, 0.2761504650115967]\nUsing mean=(0.5070751905441284, 0.48654890060424805, 0.44091787934303284), std=(0.2673342823982239, 0.2564384639263153, 0.2761504650115967)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# BLOCK 2 — Model and optimizer updates (stable setup with safe learning dynamics)\n\nimport math\nfrom torch.optim.swa_utils import AveragedModel, SWALR\n\n# === Model (unchanged) ===\nclass VGG13(nn.Module):\n    def __init__(self):\n        super(VGG13, self).__init__()\n        self.layers = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            nn.Flatten(),\n            nn.Linear(512, 100)\n        )\n\n    def forward(self, x: Tensor) -> Tensor:\n        return self.layers(x)\n\n\n# === Experiment configurations (safe & diverse) ===\nexperiments = [\n    # 1️⃣ Baseline — balanced setup\n    {\n        \"name\": \"exp1_baseline\",\n        \"base_lr\": 0.15,\n        \"ema_decay\": 0.9995,\n        \"rand_mag\": 9,\n        \"mix_p\": 0.8,\n        \"extra_aug\": False,\n        \"remove_ema\": False,\n        \"wd\": 5e-4,\n    },\n\n    # 2️⃣ Strong augmentation — robustness-focused\n    {\n        \"name\": \"exp2_strong_aug\",\n        \"base_lr\": 0.12,\n        \"ema_decay\": 0.9995,\n        \"rand_mag\": 14,\n        \"mix_p\": 0.8,\n        \"extra_aug\": True,\n        \"remove_ema\": False,\n        \"wd\": 5e-4,\n    },\n\n    # 3️⃣ Fast optimization — slightly higher LR but stable decay\n    {\n        \"name\": \"exp3_fast_opt\",\n        \"base_lr\": 0.10,          \n        \"ema_decay\": 0.9975,      \n        \"rand_mag\": 9,\n        \"mix_p\": 0.6,\n        \"extra_aug\": False,\n        \"remove_ema\": False,\n        \"wd\": 6e-4,\n    },\n\n    # 4️⃣ Weak augmentation + light regularization\n    {\n        \"name\": \"exp4_light_aug_fast_lr\",\n        \"base_lr\": 0.10,          \n        \"ema_decay\": 0.998,\n        \"rand_mag\": 6,\n        \"mix_p\": 0.5,\n        \"extra_aug\": False,\n        \"remove_ema\": False,\n        \"wd\": 5e-4,\n    },\n]\n\n\n# === Global training constants ===\ncriterion = nn.CrossEntropyLoss(label_smoothing=0.02)\n\nEPOCHS = 100\nwarmup_pct = 0.20             \nmin_lr_ratio = 1e-4\ngrad_clip = 0.5               \npatience = 20\nSWA_START_RATIO = 0.75        \n\n# ✅ For reproducibility\ntorch.backends.cudnn.deterministic = False\ntorch.backends.cudnn.benchmark = True\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T23:23:02.439329Z","iopub.execute_input":"2025-10-29T23:23:02.439710Z","iopub.status.idle":"2025-10-29T23:23:02.451846Z","shell.execute_reply.started":"2025-10-29T23:23:02.439683Z","shell.execute_reply":"2025-10-29T23:23:02.451022Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# BLOCK 3 — Training Loop (stabilized: FP16-safe, NaN-guarded, consistent EMA/SWA updates)\n\nfrom torch.optim.swa_utils import update_bn\nimport os, torch\n\ndef ensure_nchw(x: torch.Tensor) -> torch.Tensor:\n    if x.ndim == 4 and x.shape[1] != 3 and x.shape[-1] == 3:\n        return x.permute(0, 3, 1, 2).contiguous()\n    return x\n\n\ndef accuracy(outputs: torch.Tensor, targets: torch.Tensor) -> float:\n    with torch.no_grad():\n        preds = outputs.argmax(1)\n        return (preds == targets).float().mean().item()\n\n\n# === Mixup / CutMix helpers ===\ndef rand_bbox(W, H, lam):\n    cut_rat = (1.0 - lam) ** 0.5\n    cut_w = int(W * cut_rat)\n    cut_h = int(H * cut_rat)\n    cx, cy = np.random.randint(W), np.random.randint(H)\n    x1, y1 = np.clip(cx - cut_w // 2, 0, W), np.clip(cy - cut_h // 2, 0, H)\n    x2, y2 = np.clip(cx + cut_w // 2, 0, W), np.clip(cy + cut_h // 2, 0, H)\n    return x1, y1, x2, y2\n\n\ndef apply_mixup_cutmix(inputs, targets, mixup_alpha=0.4, cutmix_alpha=1.0, p=0.9):\n    if np.random.rand() > p:\n        return inputs, (targets, targets, 1.0), None\n    bs, c, h, w = inputs.size()\n    idx = torch.randperm(bs, device=inputs.device)\n    y_a, y_b = targets, targets[idx]\n    if np.random.rand() < 0.5:\n        lam = np.random.beta(mixup_alpha, mixup_alpha)\n        mixed = inputs * lam + inputs[idx] * (1.0 - lam)\n        return mixed, (y_a, y_b, float(lam)), \"mixup\"\n    else:\n        lam = np.random.beta(cutmix_alpha, cutmix_alpha)\n        x1, y1, x2, y2 = rand_bbox(w, h, lam)\n        mixed = inputs.clone()\n        mixed[:, :, y1:y2, x1:x2] = inputs[idx, :, y1:y2, x1:x2]\n        lam = 1.0 - ((x2 - x1) * (y2 - y1) / (w * h + 1e-9))\n        return mixed, (y_a, y_b, float(lam)), \"cutmix\"\n\n\ndef mix_criterion(crit, preds, y_a, y_b, lam):\n    return lam * crit(preds, y_a) + (1.0 - lam) * crit(preds, y_b)\n\n\n# === Stable training step ===\ndef run_epoch(loader, model, optimizer, scheduler, ema, criterion, train_mode=True, use_swa=False, mix_p=0.9):\n    model.train(train_mode)\n    total_loss, total_acc, total_n = 0.0, 0.0, 0\n    bar = tqdm(loader, leave=False)\n    for inputs, targets in bar:\n        inputs = ensure_nchw(inputs.to(device, non_blocking=True)).float()\n        targets = targets.to(device, non_blocking=True)\n\n        if train_mode:\n            inputs_mixed, (y_a, y_b, lam), mode = apply_mixup_cutmix(inputs, targets, p=mix_p)\n\n            with torch.autocast(device_type=device.type, enabled=enable_half):\n                outputs = model(inputs_mixed)\n                loss = criterion(outputs, targets) if mode is None else mix_criterion(criterion, outputs, y_a, y_b, lam)\n\n            # ✅ skip if NaN/Inf\n            if not torch.isfinite(loss):\n                print(\"⚠️  Skipping batch due to NaN/Inf loss\")\n                optimizer.zero_grad(set_to_none=True)\n                continue\n\n            scaler.scale(loss).backward()\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad(set_to_none=True)\n\n            if not use_swa:\n                scheduler.step()\n            if ema is not None:\n                ema.update(model)\n\n            batch_acc = accuracy(outputs, targets)\n\n        else:\n            with torch.inference_mode(), torch.autocast(device_type=device.type, enabled=enable_half):\n                net = ema.ema if ema is not None else model\n                outputs = net(inputs)\n                loss = criterion(outputs, targets)\n            batch_acc = accuracy(outputs, targets)\n\n        bs = targets.size(0)\n        total_loss += loss.item() * bs\n        total_acc += batch_acc * bs\n        total_n += bs\n        bar.set_description(f\"{'Train' if train_mode else 'Valid'} loss {total_loss/total_n:.4f} acc {total_acc/total_n:.4f}\")\n\n    return total_loss / total_n, total_acc / total_n\n\n\n# === EMA wrapper ===\nclass ModelEMA:\n    def __init__(self, model, decay=0.9995):\n        self.ema = VGG13().to(device)\n        self.ema.load_state_dict(model.state_dict(), strict=True)\n        for p in self.ema.parameters():\n            p.requires_grad_(False)\n        self.decay = decay\n\n    @torch.no_grad()\n    def update(self, model):\n        d = self.decay\n        msd = model.state_dict()\n        for k, v in self.ema.state_dict().items():\n            if v.dtype.is_floating_point:\n                v.copy_(v * d + (1.0 - d) * msd[k])\n\n    def state_dict(self):\n        return self.ema.state_dict()\n\n\n# === Run all experiments ===\nfor cfg in experiments:\n    print(f\"\\n\\n=== Running {cfg['name']} ===\")\n\n    # Dynamic augmentations\n    extra_layers = []\n    if cfg.get(\"extra_aug\", False):\n        extra_layers += [\n            v2.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 1.0)),\n            v2.RandomPerspective(distortion_scale=0.5, p=0.5),\n        ]\n\n    train_transforms = v2.Compose([\n        v2.ToImage(),\n        v2.RandomCrop(32, padding=4, padding_mode=\"reflect\"),\n        v2.RandomAffine(degrees=10, translate=(0.12, 0.12), scale=(0.9, 1.1)),\n        v2.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n        *extra_layers,\n        v2.ToDtype(torch.float32, scale=True),\n        v2.Normalize(mean, std, inplace=True),\n        v2.RandomErasing(p=0.4, scale=(0.02, 0.15), ratio=(0.3, 3.3), inplace=True),\n        v2.RandAugment(num_ops=2, magnitude=cfg[\"rand_mag\"]),\n    ])\n\n    # Fresh datasets\n    base_train = SVHN_Dataset(train=True, transforms=None)\n    val_len = int(len(base_train) * 0.10)\n    train_len = len(base_train) - val_len\n    train_subset, val_subset = random_split(base_train, [train_len, val_len], generator=torch.Generator().manual_seed(seed))\n    train_set = TransformedSubset(train_subset, train_transforms)\n    val_set = TransformedSubset(val_subset, eval_transforms)\n\n    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=pin, drop_last=True)\n    val_loader = DataLoader(val_set, batch_size=512, shuffle=False, num_workers=NUM_WORKERS, pin_memory=pin)\n\n    # === Model & optimizer ===\n    model = VGG13().to(device)\n    model = torch.jit.script(model)\n    ema = None if cfg.get(\"remove_ema\", False) else ModelEMA(model, decay=cfg[\"ema_decay\"])\n    base_lr = cfg[\"base_lr\"]\n\n    optimizer = optim.SGD(\n        model.parameters(),\n        lr=base_lr,\n        momentum=0.9,\n        weight_decay=cfg.get(\"wd\", 5e-4),\n        nesterov=True,\n        fused=(device.type == \"cuda\")\n    )\n\n    # === Scheduler ===\n    total_steps = EPOCHS * len(train_loader)\n    warmup_steps = max(1, int(total_steps * warmup_pct))\n\n    def lr_lambda(step):\n        if step < warmup_steps:\n            return float(step + 1) / float(warmup_steps)\n        progress = (step - warmup_steps) / max(1, total_steps - warmup_steps)\n        return min_lr_ratio + (1.0 - min_lr_ratio) * 0.5 * (1.0 + math.cos(math.pi * progress))\n\n    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n\n    # === SWA setup ===\n    swa_start_epoch = int(EPOCHS * SWA_START_RATIO)\n    swa_model = AveragedModel(model)\n    swa_scheduler = SWALR(optimizer, swa_lr=base_lr * 0.05)\n\n    best_val_loss, best_epoch, no_improve = float(\"inf\"), -1, 0\n    save_dir = f\"/kaggle/working/{cfg['name']}\"\n    os.makedirs(save_dir, exist_ok=True)\n\n    # === Epoch loop ===\n    for epoch in range(1, EPOCHS + 1):\n        use_swa = epoch >= swa_start_epoch\n        tr_loss, tr_acc = run_epoch(train_loader, model, optimizer, scheduler, ema, criterion, train_mode=True, use_swa=use_swa, mix_p=cfg[\"mix_p\"])\n        va_loss, va_acc = run_epoch(val_loader, model, optimizer, scheduler, ema, criterion, train_mode=False, use_swa=use_swa)\n\n        lr_now = optimizer.param_groups[0][\"lr\"]\n        print(f\"[{cfg['name']}] Epoch {epoch:03d}/{EPOCHS} | lr={lr_now:.5f} | train_acc={tr_acc*100:.2f}% | val_acc={va_acc*100:.2f}% | val_loss={va_loss:.4f}\")\n\n        if use_swa:\n            swa_model.update_parameters(model)\n            swa_scheduler.step()\n\n        if torch.isnan(torch.tensor(va_loss)) or va_loss == float(\"inf\"):\n            print(f\"⚠️  NaN validation loss detected in {cfg['name']} — reducing LR.\")\n            for g in optimizer.param_groups:\n                g[\"lr\"] *= 0.5\n            continue\n\n        improved = va_loss < best_val_loss - 1e-4\n        if improved:\n            best_val_loss, best_epoch, no_improve = va_loss, epoch, 0\n            torch.save((ema.state_dict() if ema else model.state_dict()), f\"{save_dir}/best_vgg13.pth\")\n        else:\n            no_improve += 1\n            if no_improve >= patience:\n                print(f\"[{cfg['name']}] Early stopping at epoch {epoch} (best {best_epoch}, val_loss {best_val_loss:.4f}).\")\n                break\n\n    # === SWA finalize ===\n    print(f\"Finalizing {cfg['name']} with SWA update...\")\n    swa_model.train()\n    update_bn(train_loader, swa_model)\n    swa_model.eval()\n\n    @torch.inference_mode()\n    def eval_on_val(module):\n        tot_loss, tot_acc, tot_n = 0.0, 0.0, 0\n        for inputs, targets in val_loader:\n            inputs = ensure_nchw(inputs.to(device, non_blocking=True)).float()\n            targets = targets.to(device, non_blocking=True)\n            with torch.autocast(device_type=device.type, enabled=enable_half):\n                outputs = module(inputs)\n                loss = criterion(outputs, targets)\n            bs = targets.size(0)\n            tot_loss += loss.item() * bs\n            tot_acc += accuracy(outputs, targets) * bs\n            tot_n += bs\n        return tot_loss / tot_n, tot_acc / tot_n\n\n    swa_val_loss, swa_val_acc = eval_on_val(swa_model)\n    print(f\"[{cfg['name']}] SWA val_loss={swa_val_loss:.4f}, val_acc={swa_val_acc*100:.2f}% | best EMA loss={best_val_loss:.4f}\")\n\n    if swa_val_loss < best_val_loss - 1e-4:\n        torch.save(swa_model.state_dict(), f\"{save_dir}/best_vgg13.pth\")\n        print(f\"[{cfg['name']}] SWA outperformed EMA — saved SWA weights.\")\n    else:\n        print(f\"[{cfg['name']}] Keeping EMA weights.\")\n\nprint(\"\\nAll 4 experiments completed successfully ✅\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T23:23:02.452802Z","iopub.execute_input":"2025-10-29T23:23:02.453083Z","iopub.status.idle":"2025-10-30T00:03:20.998224Z","shell.execute_reply.started":"2025-10-29T23:23:02.453066Z","shell.execute_reply":"2025-10-30T00:03:20.997239Z"}},"outputs":[{"name":"stdout","text":"\n\n=== Running exp1_baseline ===\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 001/100 | lr=0.00754 | train_acc=3.22% | val_acc=0.90% | val_loss=4.8012\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 002/100 | lr=0.01504 | train_acc=10.85% | val_acc=1.40% | val_loss=4.7015\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 003/100 | lr=0.02254 | train_acc=16.24% | val_acc=2.08% | val_loss=4.5687\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 004/100 | lr=0.03004 | train_acc=19.64% | val_acc=4.42% | val_loss=4.4046\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 005/100 | lr=0.03754 | train_acc=23.50% | val_acc=9.36% | val_loss=4.2133\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 006/100 | lr=0.04504 | train_acc=25.17% | val_acc=14.50% | val_loss=4.0007\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 007/100 | lr=0.05254 | train_acc=30.09% | val_acc=19.30% | val_loss=3.7787\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 008/100 | lr=0.06004 | train_acc=30.37% | val_acc=23.32% | val_loss=3.5543\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 009/100 | lr=0.06754 | train_acc=34.87% | val_acc=27.56% | val_loss=3.3355\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 010/100 | lr=0.07504 | train_acc=34.76% | val_acc=31.42% | val_loss=3.1281\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 011/100 | lr=0.08254 | train_acc=38.25% | val_acc=34.00% | val_loss=2.9345\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 012/100 | lr=0.09004 | train_acc=41.49% | val_acc=36.94% | val_loss=2.7564\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 013/100 | lr=0.09754 | train_acc=44.40% | val_acc=39.60% | val_loss=2.5943\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 014/100 | lr=0.10504 | train_acc=40.91% | val_acc=42.86% | val_loss=2.4472\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 015/100 | lr=0.11254 | train_acc=46.85% | val_acc=45.32% | val_loss=2.3132\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 016/100 | lr=0.12004 | train_acc=43.79% | val_acc=47.64% | val_loss=2.1914\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 017/100 | lr=0.12754 | train_acc=44.27% | val_acc=49.62% | val_loss=2.0846\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 018/100 | lr=0.13504 | train_acc=48.09% | val_acc=51.10% | val_loss=1.9892\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 019/100 | lr=0.14254 | train_acc=47.10% | val_acc=52.86% | val_loss=1.9067\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 020/100 | lr=0.15000 | train_acc=51.03% | val_acc=54.46% | val_loss=1.8345\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 021/100 | lr=0.14994 | train_acc=49.49% | val_acc=55.70% | val_loss=1.7722\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 022/100 | lr=0.14977 | train_acc=47.98% | val_acc=56.84% | val_loss=1.7182\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 023/100 | lr=0.14948 | train_acc=49.98% | val_acc=57.82% | val_loss=1.6717\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 024/100 | lr=0.14908 | train_acc=45.62% | val_acc=58.84% | val_loss=1.6331\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 025/100 | lr=0.14856 | train_acc=46.84% | val_acc=59.76% | val_loss=1.6006\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 026/100 | lr=0.14793 | train_acc=51.04% | val_acc=60.20% | val_loss=1.5719\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 027/100 | lr=0.14718 | train_acc=54.60% | val_acc=60.64% | val_loss=1.5490\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 028/100 | lr=0.14633 | train_acc=56.22% | val_acc=61.14% | val_loss=1.5282\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 029/100 | lr=0.14536 | train_acc=54.79% | val_acc=61.88% | val_loss=1.5101\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 030/100 | lr=0.14429 | train_acc=50.53% | val_acc=62.42% | val_loss=1.4950\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 031/100 | lr=0.14311 | train_acc=53.42% | val_acc=62.60% | val_loss=1.4806\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 032/100 | lr=0.14183 | train_acc=56.88% | val_acc=63.00% | val_loss=1.4684\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 033/100 | lr=0.14044 | train_acc=56.80% | val_acc=63.14% | val_loss=1.4566\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 034/100 | lr=0.13895 | train_acc=55.24% | val_acc=63.54% | val_loss=1.4469\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 035/100 | lr=0.13736 | train_acc=57.22% | val_acc=63.80% | val_loss=1.4388\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 036/100 | lr=0.13568 | train_acc=57.51% | val_acc=64.06% | val_loss=1.4298\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 037/100 | lr=0.13390 | train_acc=55.56% | val_acc=64.30% | val_loss=1.4215\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 038/100 | lr=0.13203 | train_acc=59.71% | val_acc=64.58% | val_loss=1.4140\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 039/100 | lr=0.13008 | train_acc=57.12% | val_acc=64.70% | val_loss=1.4071\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 040/100 | lr=0.12804 | train_acc=55.63% | val_acc=64.82% | val_loss=1.4010\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 041/100 | lr=0.12591 | train_acc=56.18% | val_acc=65.20% | val_loss=1.3952\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 042/100 | lr=0.12371 | train_acc=60.22% | val_acc=65.56% | val_loss=1.3893\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 043/100 | lr=0.12143 | train_acc=60.26% | val_acc=65.72% | val_loss=1.3835\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 044/100 | lr=0.11909 | train_acc=53.82% | val_acc=66.12% | val_loss=1.3789\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 045/100 | lr=0.11667 | train_acc=56.82% | val_acc=66.16% | val_loss=1.3751\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 046/100 | lr=0.11419 | train_acc=58.83% | val_acc=66.30% | val_loss=1.3714\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 047/100 | lr=0.11165 | train_acc=56.36% | val_acc=66.52% | val_loss=1.3687\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 048/100 | lr=0.10905 | train_acc=59.88% | val_acc=66.70% | val_loss=1.3658\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 049/100 | lr=0.10640 | train_acc=60.47% | val_acc=66.98% | val_loss=1.3637\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 050/100 | lr=0.10371 | train_acc=60.14% | val_acc=66.98% | val_loss=1.3616\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 051/100 | lr=0.10096 | train_acc=66.35% | val_acc=66.96% | val_loss=1.3603\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 052/100 | lr=0.09818 | train_acc=58.46% | val_acc=67.32% | val_loss=1.3595\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 053/100 | lr=0.09536 | train_acc=54.05% | val_acc=67.38% | val_loss=1.3591\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 054/100 | lr=0.09251 | train_acc=64.65% | val_acc=67.32% | val_loss=1.3586\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 055/100 | lr=0.08964 | train_acc=60.45% | val_acc=67.62% | val_loss=1.3584\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 056/100 | lr=0.08674 | train_acc=55.29% | val_acc=67.58% | val_loss=1.3583\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 057/100 | lr=0.08382 | train_acc=57.85% | val_acc=67.74% | val_loss=1.3578\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 058/100 | lr=0.08089 | train_acc=65.10% | val_acc=67.52% | val_loss=1.3571\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 059/100 | lr=0.07795 | train_acc=55.93% | val_acc=67.74% | val_loss=1.3559\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 060/100 | lr=0.07501 | train_acc=61.25% | val_acc=67.84% | val_loss=1.3556\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 061/100 | lr=0.07206 | train_acc=60.38% | val_acc=67.98% | val_loss=1.3559\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 062/100 | lr=0.06912 | train_acc=64.30% | val_acc=67.98% | val_loss=1.3561\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 063/100 | lr=0.06619 | train_acc=63.25% | val_acc=67.94% | val_loss=1.3562\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 064/100 | lr=0.06328 | train_acc=62.54% | val_acc=67.82% | val_loss=1.3569\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 065/100 | lr=0.06038 | train_acc=61.58% | val_acc=68.12% | val_loss=1.3577\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 066/100 | lr=0.05750 | train_acc=64.48% | val_acc=68.10% | val_loss=1.3589\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 067/100 | lr=0.05465 | train_acc=64.49% | val_acc=68.20% | val_loss=1.3604\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 068/100 | lr=0.05183 | train_acc=66.65% | val_acc=68.08% | val_loss=1.3625\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 069/100 | lr=0.04905 | train_acc=70.37% | val_acc=67.98% | val_loss=1.3645\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 070/100 | lr=0.04631 | train_acc=62.02% | val_acc=68.10% | val_loss=1.3661\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 071/100 | lr=0.04361 | train_acc=63.44% | val_acc=68.18% | val_loss=1.3673\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 072/100 | lr=0.04096 | train_acc=67.29% | val_acc=68.20% | val_loss=1.3695\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 073/100 | lr=0.03836 | train_acc=68.27% | val_acc=68.28% | val_loss=1.3721\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 074/100 | lr=0.03582 | train_acc=67.61% | val_acc=68.28% | val_loss=1.3744\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 075/100 | lr=0.03582 | train_acc=62.29% | val_acc=68.38% | val_loss=1.3765\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 076/100 | lr=0.03513 | train_acc=68.85% | val_acc=68.42% | val_loss=1.3777\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 077/100 | lr=0.03312 | train_acc=64.46% | val_acc=68.54% | val_loss=1.3797\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 078/100 | lr=0.02999 | train_acc=70.97% | val_acc=68.48% | val_loss=1.3827\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 079/100 | lr=0.02604 | train_acc=71.88% | val_acc=68.68% | val_loss=1.3863\n","output_type":"stream"},{"name":"stderr","text":"                                                                               ","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Epoch 080/100 | lr=0.02166 | train_acc=68.12% | val_acc=68.78% | val_loss=1.3899\n[exp1_baseline] Early stopping at epoch 80 (best 60, val_loss 1.3556).\nFinalizing exp1_baseline with SWA update...\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] SWA val_loss=1.7216, val_acc=63.10% | best EMA loss=1.3556\n[exp1_baseline] Keeping EMA weights.\n\n\n=== Running exp2_strong_aug ===\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 001/100 | lr=0.00603 | train_acc=2.89% | val_acc=0.86% | val_loss=4.8178\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 002/100 | lr=0.01203 | train_acc=9.48% | val_acc=1.30% | val_loss=4.7229\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 003/100 | lr=0.01803 | train_acc=14.77% | val_acc=2.36% | val_loss=4.5951\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 004/100 | lr=0.02403 | train_acc=18.22% | val_acc=5.00% | val_loss=4.4415\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 005/100 | lr=0.03003 | train_acc=22.59% | val_acc=8.52% | val_loss=4.2684\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 006/100 | lr=0.03603 | train_acc=22.68% | val_acc=12.96% | val_loss=4.0781\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 007/100 | lr=0.04203 | train_acc=27.95% | val_acc=16.92% | val_loss=3.8773\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 008/100 | lr=0.04803 | train_acc=30.45% | val_acc=21.30% | val_loss=3.6720\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 009/100 | lr=0.05403 | train_acc=33.06% | val_acc=24.62% | val_loss=3.4680\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 010/100 | lr=0.06003 | train_acc=34.76% | val_acc=28.44% | val_loss=3.2708\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 011/100 | lr=0.06603 | train_acc=38.26% | val_acc=31.98% | val_loss=3.0815\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 012/100 | lr=0.07203 | train_acc=39.75% | val_acc=34.50% | val_loss=2.9042\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 013/100 | lr=0.07803 | train_acc=39.64% | val_acc=37.28% | val_loss=2.7398\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 014/100 | lr=0.08403 | train_acc=42.03% | val_acc=40.18% | val_loss=2.5879\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 015/100 | lr=0.09003 | train_acc=44.43% | val_acc=42.74% | val_loss=2.4486\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 016/100 | lr=0.09603 | train_acc=42.02% | val_acc=45.00% | val_loss=2.3221\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 017/100 | lr=0.10203 | train_acc=45.85% | val_acc=46.74% | val_loss=2.2085\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 018/100 | lr=0.10803 | train_acc=44.17% | val_acc=49.30% | val_loss=2.1083\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 019/100 | lr=0.11403 | train_acc=45.58% | val_acc=50.92% | val_loss=2.0190\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 020/100 | lr=0.12000 | train_acc=46.74% | val_acc=52.34% | val_loss=1.9386\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 021/100 | lr=0.11995 | train_acc=48.40% | val_acc=53.70% | val_loss=1.8680\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 022/100 | lr=0.11982 | train_acc=49.97% | val_acc=55.08% | val_loss=1.8078\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 023/100 | lr=0.11958 | train_acc=50.36% | val_acc=56.62% | val_loss=1.7547\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 024/100 | lr=0.11926 | train_acc=46.24% | val_acc=57.76% | val_loss=1.7092\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 025/100 | lr=0.11885 | train_acc=51.20% | val_acc=58.50% | val_loss=1.6704\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 026/100 | lr=0.11834 | train_acc=52.88% | val_acc=59.20% | val_loss=1.6372\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 027/100 | lr=0.11775 | train_acc=55.03% | val_acc=59.90% | val_loss=1.6073\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 028/100 | lr=0.11706 | train_acc=58.36% | val_acc=60.46% | val_loss=1.5808\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 029/100 | lr=0.11629 | train_acc=55.84% | val_acc=61.00% | val_loss=1.5577\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 030/100 | lr=0.11543 | train_acc=61.11% | val_acc=61.58% | val_loss=1.5376\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 031/100 | lr=0.11449 | train_acc=54.06% | val_acc=62.00% | val_loss=1.5216\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 032/100 | lr=0.11346 | train_acc=59.51% | val_acc=62.60% | val_loss=1.5082\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 033/100 | lr=0.11235 | train_acc=66.29% | val_acc=62.82% | val_loss=1.4964\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 034/100 | lr=0.11116 | train_acc=59.92% | val_acc=63.06% | val_loss=1.4863\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 035/100 | lr=0.10989 | train_acc=54.54% | val_acc=63.44% | val_loss=1.4783\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 036/100 | lr=0.10854 | train_acc=55.62% | val_acc=63.64% | val_loss=1.4716\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 037/100 | lr=0.10712 | train_acc=54.63% | val_acc=63.88% | val_loss=1.4648\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 038/100 | lr=0.10563 | train_acc=54.78% | val_acc=63.94% | val_loss=1.4581\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 039/100 | lr=0.10406 | train_acc=58.24% | val_acc=64.12% | val_loss=1.4517\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 040/100 | lr=0.10243 | train_acc=62.59% | val_acc=64.04% | val_loss=1.4456\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 041/100 | lr=0.10073 | train_acc=58.07% | val_acc=64.00% | val_loss=1.4410\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 042/100 | lr=0.09897 | train_acc=60.64% | val_acc=64.26% | val_loss=1.4365\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 043/100 | lr=0.09715 | train_acc=60.10% | val_acc=64.66% | val_loss=1.4319\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 044/100 | lr=0.09527 | train_acc=59.19% | val_acc=64.92% | val_loss=1.4270\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 045/100 | lr=0.09334 | train_acc=63.85% | val_acc=64.86% | val_loss=1.4233\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 046/100 | lr=0.09135 | train_acc=57.16% | val_acc=65.08% | val_loss=1.4193\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 047/100 | lr=0.08932 | train_acc=63.10% | val_acc=65.42% | val_loss=1.4159\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 048/100 | lr=0.08724 | train_acc=65.01% | val_acc=65.68% | val_loss=1.4132\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 049/100 | lr=0.08512 | train_acc=61.75% | val_acc=65.82% | val_loss=1.4111\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 050/100 | lr=0.08296 | train_acc=67.21% | val_acc=65.82% | val_loss=1.4095\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 051/100 | lr=0.08077 | train_acc=55.15% | val_acc=65.96% | val_loss=1.4084\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 052/100 | lr=0.07855 | train_acc=56.00% | val_acc=65.90% | val_loss=1.4083\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 053/100 | lr=0.07629 | train_acc=59.24% | val_acc=65.84% | val_loss=1.4073\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 054/100 | lr=0.07401 | train_acc=63.37% | val_acc=66.02% | val_loss=1.4065\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 055/100 | lr=0.07171 | train_acc=64.37% | val_acc=66.18% | val_loss=1.4068\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 056/100 | lr=0.06939 | train_acc=61.22% | val_acc=66.38% | val_loss=1.4071\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 057/100 | lr=0.06706 | train_acc=60.48% | val_acc=66.34% | val_loss=1.4077\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 058/100 | lr=0.06471 | train_acc=63.40% | val_acc=66.60% | val_loss=1.4078\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 059/100 | lr=0.06236 | train_acc=64.29% | val_acc=66.56% | val_loss=1.4073\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 060/100 | lr=0.06001 | train_acc=67.50% | val_acc=66.72% | val_loss=1.4067\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 061/100 | lr=0.05765 | train_acc=61.21% | val_acc=66.92% | val_loss=1.4070\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 062/100 | lr=0.05530 | train_acc=62.67% | val_acc=66.96% | val_loss=1.4080\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 063/100 | lr=0.05295 | train_acc=64.40% | val_acc=67.22% | val_loss=1.4088\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 064/100 | lr=0.05062 | train_acc=67.93% | val_acc=67.20% | val_loss=1.4100\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 065/100 | lr=0.04830 | train_acc=66.66% | val_acc=67.12% | val_loss=1.4124\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 066/100 | lr=0.04600 | train_acc=64.23% | val_acc=67.18% | val_loss=1.4149\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 067/100 | lr=0.04372 | train_acc=66.27% | val_acc=67.38% | val_loss=1.4165\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 068/100 | lr=0.04147 | train_acc=68.23% | val_acc=67.46% | val_loss=1.4178\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 069/100 | lr=0.03924 | train_acc=65.27% | val_acc=67.40% | val_loss=1.4196\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 070/100 | lr=0.03705 | train_acc=66.39% | val_acc=67.38% | val_loss=1.4219\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 071/100 | lr=0.03489 | train_acc=67.83% | val_acc=67.42% | val_loss=1.4243\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 072/100 | lr=0.03277 | train_acc=65.85% | val_acc=67.36% | val_loss=1.4271\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 073/100 | lr=0.03069 | train_acc=65.92% | val_acc=67.34% | val_loss=1.4297\n","output_type":"stream"},{"name":"stderr","text":"                                                                               ","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Epoch 074/100 | lr=0.02866 | train_acc=66.55% | val_acc=67.44% | val_loss=1.4327\n[exp2_strong_aug] Early stopping at epoch 74 (best 54, val_loss 1.4065).\nFinalizing exp2_strong_aug with SWA update...\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] SWA val_loss=4.6059, val_acc=0.98% | best EMA loss=1.4065\n[exp2_strong_aug] Keeping EMA weights.\n\n\n=== Running exp3_fast_opt ===\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 001/100 | lr=0.00503 | train_acc=2.80% | val_acc=0.86% | val_loss=4.7181\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 002/100 | lr=0.01003 | train_acc=9.88% | val_acc=6.12% | val_loss=4.3543\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 003/100 | lr=0.01503 | train_acc=15.33% | val_acc=14.58% | val_loss=3.9385\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 004/100 | lr=0.02003 | train_acc=21.08% | val_acc=20.64% | val_loss=3.5620\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 005/100 | lr=0.02503 | train_acc=23.95% | val_acc=25.28% | val_loss=3.2511\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 006/100 | lr=0.03003 | train_acc=25.65% | val_acc=29.54% | val_loss=2.9901\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 007/100 | lr=0.03503 | train_acc=32.36% | val_acc=34.50% | val_loss=2.7566\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 008/100 | lr=0.04003 | train_acc=37.82% | val_acc=38.28% | val_loss=2.5487\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 009/100 | lr=0.04503 | train_acc=37.30% | val_acc=42.56% | val_loss=2.3721\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 010/100 | lr=0.05003 | train_acc=45.06% | val_acc=45.56% | val_loss=2.2234\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 011/100 | lr=0.05503 | train_acc=43.09% | val_acc=48.36% | val_loss=2.0980\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 012/100 | lr=0.06003 | train_acc=46.71% | val_acc=50.44% | val_loss=1.9949\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 013/100 | lr=0.06503 | train_acc=49.16% | val_acc=52.40% | val_loss=1.9049\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 014/100 | lr=0.07003 | train_acc=54.75% | val_acc=54.46% | val_loss=1.8295\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 015/100 | lr=0.07503 | train_acc=55.86% | val_acc=55.94% | val_loss=1.7654\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 016/100 | lr=0.08003 | train_acc=52.69% | val_acc=57.00% | val_loss=1.7174\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 017/100 | lr=0.08503 | train_acc=51.58% | val_acc=58.28% | val_loss=1.6783\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 018/100 | lr=0.09003 | train_acc=63.14% | val_acc=59.24% | val_loss=1.6393\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 019/100 | lr=0.09503 | train_acc=57.23% | val_acc=59.98% | val_loss=1.6089\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 020/100 | lr=0.10000 | train_acc=59.51% | val_acc=60.50% | val_loss=1.5838\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 021/100 | lr=0.09996 | train_acc=56.50% | val_acc=61.06% | val_loss=1.5603\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 022/100 | lr=0.09985 | train_acc=59.77% | val_acc=61.64% | val_loss=1.5404\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 023/100 | lr=0.09965 | train_acc=63.82% | val_acc=62.08% | val_loss=1.5180\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 024/100 | lr=0.09938 | train_acc=59.76% | val_acc=62.90% | val_loss=1.5042\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 025/100 | lr=0.09904 | train_acc=56.76% | val_acc=63.18% | val_loss=1.4924\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 026/100 | lr=0.09862 | train_acc=63.44% | val_acc=63.00% | val_loss=1.4846\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 027/100 | lr=0.09812 | train_acc=67.59% | val_acc=63.14% | val_loss=1.4826\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 028/100 | lr=0.09755 | train_acc=64.49% | val_acc=63.04% | val_loss=1.4808\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 029/100 | lr=0.09691 | train_acc=67.45% | val_acc=63.42% | val_loss=1.4795\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 030/100 | lr=0.09619 | train_acc=72.11% | val_acc=63.88% | val_loss=1.4798\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 031/100 | lr=0.09541 | train_acc=69.75% | val_acc=63.92% | val_loss=1.4835\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 032/100 | lr=0.09455 | train_acc=60.54% | val_acc=64.22% | val_loss=1.4875\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 033/100 | lr=0.09363 | train_acc=70.58% | val_acc=63.96% | val_loss=1.4912\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 034/100 | lr=0.09263 | train_acc=62.83% | val_acc=64.30% | val_loss=1.4980\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 035/100 | lr=0.09157 | train_acc=70.71% | val_acc=64.06% | val_loss=1.5012\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 036/100 | lr=0.09045 | train_acc=66.23% | val_acc=64.30% | val_loss=1.5033\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 037/100 | lr=0.08927 | train_acc=68.52% | val_acc=63.90% | val_loss=1.5058\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 038/100 | lr=0.08802 | train_acc=67.92% | val_acc=64.08% | val_loss=1.5112\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 039/100 | lr=0.08672 | train_acc=66.92% | val_acc=64.22% | val_loss=1.5145\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 040/100 | lr=0.08536 | train_acc=67.41% | val_acc=64.64% | val_loss=1.5193\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 041/100 | lr=0.08394 | train_acc=68.09% | val_acc=64.94% | val_loss=1.5165\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 042/100 | lr=0.08247 | train_acc=70.31% | val_acc=65.14% | val_loss=1.5124\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 043/100 | lr=0.08096 | train_acc=67.90% | val_acc=64.86% | val_loss=1.5125\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 044/100 | lr=0.07939 | train_acc=68.29% | val_acc=65.16% | val_loss=1.5149\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 045/100 | lr=0.07778 | train_acc=62.18% | val_acc=64.82% | val_loss=1.5189\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 046/100 | lr=0.07613 | train_acc=68.56% | val_acc=64.76% | val_loss=1.5199\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 047/100 | lr=0.07443 | train_acc=68.11% | val_acc=64.80% | val_loss=1.5228\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 048/100 | lr=0.07270 | train_acc=68.71% | val_acc=64.88% | val_loss=1.5200\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Epoch 049/100 | lr=0.07094 | train_acc=69.94% | val_acc=64.84% | val_loss=1.5193\n[exp3_fast_opt] Early stopping at epoch 49 (best 29, val_loss 1.4795).\nFinalizing exp3_fast_opt with SWA update...\n[exp3_fast_opt] SWA val_loss=4.6058, val_acc=0.94% | best EMA loss=1.4795\n[exp3_fast_opt] Keeping EMA weights.\n\n\n=== Running exp4_light_aug_fast_lr ===\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 001/100 | lr=0.00503 | train_acc=2.77% | val_acc=0.68% | val_loss=4.8111\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 002/100 | lr=0.01003 | train_acc=11.77% | val_acc=3.20% | val_loss=4.4673\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 003/100 | lr=0.01503 | train_acc=17.75% | val_acc=12.00% | val_loss=4.0674\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 004/100 | lr=0.02003 | train_acc=22.98% | val_acc=19.04% | val_loss=3.6829\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 005/100 | lr=0.02503 | train_acc=27.52% | val_acc=24.70% | val_loss=3.3433\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 006/100 | lr=0.03003 | train_acc=31.66% | val_acc=29.38% | val_loss=3.0514\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 007/100 | lr=0.03503 | train_acc=34.82% | val_acc=33.46% | val_loss=2.8028\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 008/100 | lr=0.04003 | train_acc=37.88% | val_acc=37.36% | val_loss=2.5922\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 009/100 | lr=0.04503 | train_acc=40.94% | val_acc=41.34% | val_loss=2.4121\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 010/100 | lr=0.05003 | train_acc=44.94% | val_acc=44.74% | val_loss=2.2617\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 011/100 | lr=0.05503 | train_acc=46.61% | val_acc=47.44% | val_loss=2.1396\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 012/100 | lr=0.06003 | train_acc=52.47% | val_acc=49.70% | val_loss=2.0357\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 013/100 | lr=0.06503 | train_acc=53.04% | val_acc=51.34% | val_loss=1.9504\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 014/100 | lr=0.07003 | train_acc=55.30% | val_acc=52.42% | val_loss=1.8826\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 015/100 | lr=0.07503 | train_acc=60.52% | val_acc=53.88% | val_loss=1.8242\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 016/100 | lr=0.08003 | train_acc=59.08% | val_acc=55.14% | val_loss=1.7762\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 017/100 | lr=0.08503 | train_acc=58.86% | val_acc=55.94% | val_loss=1.7394\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 018/100 | lr=0.09003 | train_acc=58.59% | val_acc=56.42% | val_loss=1.7082\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 019/100 | lr=0.09503 | train_acc=62.65% | val_acc=57.34% | val_loss=1.6794\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 020/100 | lr=0.10000 | train_acc=59.40% | val_acc=58.00% | val_loss=1.6542\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 021/100 | lr=0.09996 | train_acc=67.48% | val_acc=58.60% | val_loss=1.6274\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 022/100 | lr=0.09985 | train_acc=70.12% | val_acc=59.56% | val_loss=1.6087\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 023/100 | lr=0.09965 | train_acc=67.71% | val_acc=60.44% | val_loss=1.5911\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 024/100 | lr=0.09938 | train_acc=70.93% | val_acc=60.80% | val_loss=1.5794\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 025/100 | lr=0.09904 | train_acc=66.52% | val_acc=61.18% | val_loss=1.5672\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 026/100 | lr=0.09862 | train_acc=69.54% | val_acc=61.38% | val_loss=1.5577\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 027/100 | lr=0.09812 | train_acc=72.07% | val_acc=61.68% | val_loss=1.5527\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 028/100 | lr=0.09755 | train_acc=72.38% | val_acc=61.72% | val_loss=1.5462\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 029/100 | lr=0.09691 | train_acc=70.25% | val_acc=62.22% | val_loss=1.5394\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 030/100 | lr=0.09619 | train_acc=76.34% | val_acc=62.28% | val_loss=1.5363\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 031/100 | lr=0.09541 | train_acc=76.08% | val_acc=62.60% | val_loss=1.5384\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 032/100 | lr=0.09455 | train_acc=75.23% | val_acc=62.72% | val_loss=1.5378\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 033/100 | lr=0.09363 | train_acc=75.64% | val_acc=62.70% | val_loss=1.5377\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 034/100 | lr=0.09263 | train_acc=72.58% | val_acc=63.14% | val_loss=1.5330\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 035/100 | lr=0.09157 | train_acc=74.84% | val_acc=63.40% | val_loss=1.5339\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 036/100 | lr=0.09045 | train_acc=68.08% | val_acc=63.26% | val_loss=1.5311\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 037/100 | lr=0.08927 | train_acc=72.46% | val_acc=63.44% | val_loss=1.5348\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 038/100 | lr=0.08802 | train_acc=78.38% | val_acc=63.38% | val_loss=1.5366\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 039/100 | lr=0.08672 | train_acc=74.78% | val_acc=63.36% | val_loss=1.5395\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 040/100 | lr=0.08536 | train_acc=63.19% | val_acc=63.86% | val_loss=1.5413\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 041/100 | lr=0.08394 | train_acc=75.61% | val_acc=63.54% | val_loss=1.5419\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 042/100 | lr=0.08247 | train_acc=79.93% | val_acc=63.30% | val_loss=1.5461\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 043/100 | lr=0.08096 | train_acc=74.80% | val_acc=63.62% | val_loss=1.5498\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 044/100 | lr=0.07939 | train_acc=73.33% | val_acc=63.76% | val_loss=1.5530\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 045/100 | lr=0.07778 | train_acc=71.59% | val_acc=63.64% | val_loss=1.5540\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 046/100 | lr=0.07613 | train_acc=73.72% | val_acc=63.86% | val_loss=1.5563\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 047/100 | lr=0.07443 | train_acc=72.16% | val_acc=63.80% | val_loss=1.5584\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 048/100 | lr=0.07270 | train_acc=73.17% | val_acc=64.02% | val_loss=1.5566\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 049/100 | lr=0.07094 | train_acc=73.63% | val_acc=63.88% | val_loss=1.5567\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 050/100 | lr=0.06914 | train_acc=74.71% | val_acc=63.90% | val_loss=1.5603\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 051/100 | lr=0.06731 | train_acc=73.45% | val_acc=63.84% | val_loss=1.5575\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 052/100 | lr=0.06545 | train_acc=73.99% | val_acc=64.14% | val_loss=1.5588\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 053/100 | lr=0.06358 | train_acc=76.31% | val_acc=64.32% | val_loss=1.5633\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 054/100 | lr=0.06168 | train_acc=75.07% | val_acc=64.24% | val_loss=1.5632\n","output_type":"stream"},{"name":"stderr","text":"                                                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 055/100 | lr=0.05976 | train_acc=79.97% | val_acc=64.14% | val_loss=1.5682\n","output_type":"stream"},{"name":"stderr","text":"                                                                               ","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Epoch 056/100 | lr=0.05783 | train_acc=73.98% | val_acc=64.40% | val_loss=1.5694\n[exp4_light_aug_fast_lr] Early stopping at epoch 56 (best 36, val_loss 1.5311).\nFinalizing exp4_light_aug_fast_lr with SWA update...\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] SWA val_loss=4.6061, val_acc=0.96% | best EMA loss=1.5311\n[exp4_light_aug_fast_lr] Keeping EMA weights.\n\nAll 4 experiments completed successfully ✅\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# BLOCK 4 — Robust Inference (multi-experiment TTA with BN recalibration and bias debiasing)\n\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom torch.optim.swa_utils import update_bn\n\ndef preprocess_for_model(x: torch.Tensor) -> torch.Tensor:\n    x = x.to(device, non_blocking=True)\n    if x.ndim == 4 and x.shape[1] != 3 and x.shape[-1] == 3:\n        x = x.permute(0, 3, 1, 2).contiguous()\n    return x.float()\n\n\n@torch.inference_mode()\ndef inference_tta(model):\n    \"\"\"Performs TTA inference with adaptive BN + logit debiasing.\"\"\"\n    # ✅ Recalibrate BatchNorm statistics before inference\n    print(\"↻ Updating BatchNorm stats on test loader for better TTA consistency...\")\n    update_bn(test_loader, model, device=device)\n\n    model.train()  # allow BN to adapt for each TTA variation\n    preds = []\n\n    tta_transforms = [\n        v2.Identity(),\n        v2.RandomHorizontalFlip(p=1.0),\n        v2.RandomAffine(degrees=0, translate=(0.1, 0), scale=None),\n        v2.RandomAffine(degrees=0, translate=(0, 0.1), scale=None),\n    ]\n\n    for inputs, _ in tqdm(test_loader, leave=False):\n        x_raw = inputs\n        augmented_logits = []\n        for t in tta_transforms:\n            # Apply transform safely\n            x = torch.stack([t(xi) for xi in x_raw])\n            x = preprocess_for_model(x)\n\n            # ✅ Force FP32 precision for stable inference\n            with torch.no_grad():\n                logits = model(x)\n\n                # ✅ Debias the final linear layer\n                last_linear = next((mod for mod in reversed(list(model.modules())) if isinstance(mod, nn.Linear)), None)\n                if last_linear is not None and hasattr(last_linear, \"bias\") and last_linear.bias is not None:\n                    bias_vec = last_linear.bias.detach().view(1, -1)\n                    logits = logits - bias_vec\n\n                augmented_logits.append(logits)\n\n        # Average predictions from all TTA views\n        avg_logits = torch.stack(augmented_logits).mean(dim=0)\n        preds.extend(torch.argmax(avg_logits, dim=1).tolist())\n\n    model.eval()\n    return preds\n\n\n# === Run inference for all experiments ===\nfor cfg in experiments:\n    exp_dir = f\"/kaggle/working/{cfg['name']}\"\n    best_path = f\"{exp_dir}/best_vgg13.pth\"\n\n    if not os.path.exists(best_path):\n        print(f\"[{cfg['name']}] ⚠️ Skipped — no best_vgg13.pth found.\")\n        continue\n\n    print(f\"\\n=== Inference for {cfg['name']} ===\")\n\n    # ✅ Load model safely in FP32\n    model = VGG13().to(device).float()\n    state_dict = torch.load(best_path, map_location=device)\n    model.load_state_dict(state_dict, strict=True)\n    model.eval()\n\n    # ✅ Optional TorchScript compilation\n    scripted = torch.jit.script(model)\n    scripted_path = f\"{exp_dir}/best_vgg13_scripted.pt\"\n    scripted.save(scripted_path)\n    print(f\"[{cfg['name']}] Saved scripted model → {scripted_path}\")\n\n    torch.cuda.empty_cache()\n\n    # ✅ Run robust TTA inference\n    preds = inference_tta(model)\n\n    # 🔍 Fallback check: if model collapsed to single-class output\n    vals, cnts = np.unique(np.array(preds), return_counts=True)\n    if len(vals) == 1:\n        print(f\"⚠️ Warning: model predicted only one class ({vals[0]}). Check training stability.\")\n        # Try disabling bias correction and re-run once\n        preds = []\n        model.eval()\n        for inputs, _ in tqdm(test_loader, leave=False):\n            x = preprocess_for_model(inputs)\n            with torch.no_grad():\n                logits = model(x)\n            preds.extend(torch.argmax(logits, dim=1).tolist())\n        vals, cnts = np.unique(np.array(preds), return_counts=True)\n\n    # === Log results ===\n    print(f\"[{cfg['name']}] Sample preds (first 20): {preds[:20]}\")\n    hist = list(zip(vals[:10].tolist(), cnts[:10].tolist()))\n    print(f\"[{cfg['name']}] Pred histogram (top 10): {hist}\")\n\n    # === Save submission ===\n    out_csv = f\"{exp_dir}/submission.csv\"\n    pd.DataFrame({\"ID\": list(range(len(preds))), \"target\": preds}).to_csv(out_csv, index=False)\n    print(f\"[{cfg['name']}] Saved submission → {out_csv}\")\n\nprint(\"\\n✅ All experiment inferences completed successfully with stable TTA and BN recalibration.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T00:03:20.999634Z","iopub.execute_input":"2025-10-30T00:03:21.000006Z","iopub.status.idle":"2025-10-30T00:04:12.861319Z","shell.execute_reply.started":"2025-10-30T00:03:20.999980Z","shell.execute_reply":"2025-10-30T00:04:12.860489Z"}},"outputs":[{"name":"stdout","text":"\n=== Inference for exp1_baseline ===\n[exp1_baseline] Saved scripted model → /kaggle/working/exp1_baseline/best_vgg13_scripted.pt\n↻ Updating BatchNorm stats on test loader for better TTA consistency...\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp1_baseline] Sample preds (first 20): [98, 50, 61, 6, 7, 33, 15, 21, 0, 98, 28, 25, 60, 27, 3, 5, 19, 57, 83, 40]\n[exp1_baseline] Pred histogram (top 10): [(0, 99), (1, 92), (2, 115), (3, 114), (4, 93), (5, 107), (6, 94), (7, 100), (8, 96), (9, 93)]\n[exp1_baseline] Saved submission → /kaggle/working/exp1_baseline/submission.csv\n\n=== Inference for exp2_strong_aug ===\n[exp2_strong_aug] Saved scripted model → /kaggle/working/exp2_strong_aug/best_vgg13_scripted.pt\n↻ Updating BatchNorm stats on test loader for better TTA consistency...\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp2_strong_aug] Sample preds (first 20): [98, 50, 61, 6, 59, 33, 15, 21, 94, 98, 28, 41, 60, 27, 3, 83, 19, 57, 83, 40]\n[exp2_strong_aug] Pred histogram (top 10): [(0, 100), (1, 74), (2, 103), (3, 132), (4, 97), (5, 120), (6, 95), (7, 85), (8, 94), (9, 94)]\n[exp2_strong_aug] Saved submission → /kaggle/working/exp2_strong_aug/submission.csv\n\n=== Inference for exp3_fast_opt ===\n[exp3_fast_opt] Saved scripted model → /kaggle/working/exp3_fast_opt/best_vgg13_scripted.pt\n↻ Updating BatchNorm stats on test loader for better TTA consistency...\n","output_type":"stream"},{"name":"stderr","text":"                                               \r","output_type":"stream"},{"name":"stdout","text":"[exp3_fast_opt] Sample preds (first 20): [98, 50, 61, 6, 64, 33, 18, 21, 98, 98, 28, 41, 60, 27, 3, 5, 19, 57, 83, 40]\n[exp3_fast_opt] Pred histogram (top 10): [(0, 99), (1, 86), (2, 100), (3, 113), (4, 101), (5, 108), (6, 94), (7, 89), (8, 100), (9, 82)]\n[exp3_fast_opt] Saved submission → /kaggle/working/exp3_fast_opt/submission.csv\n\n=== Inference for exp4_light_aug_fast_lr ===\n[exp4_light_aug_fast_lr] Saved scripted model → /kaggle/working/exp4_light_aug_fast_lr/best_vgg13_scripted.pt\n↻ Updating BatchNorm stats on test loader for better TTA consistency...\n","output_type":"stream"},{"name":"stderr","text":"                                               ","output_type":"stream"},{"name":"stdout","text":"[exp4_light_aug_fast_lr] Sample preds (first 20): [1, 50, 61, 6, 59, 33, 18, 9, 98, 98, 28, 41, 60, 27, 3, 5, 19, 57, 83, 40]\n[exp4_light_aug_fast_lr] Pred histogram (top 10): [(0, 90), (1, 95), (2, 100), (3, 123), (4, 87), (5, 110), (6, 93), (7, 76), (8, 115), (9, 97)]\n[exp4_light_aug_fast_lr] Saved submission → /kaggle/working/exp4_light_aug_fast_lr/submission.csv\n\n✅ All experiment inferences completed successfully with stable TTA and BN recalibration.\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":4}]}